{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs Dataset Exploration\n",
    "\n",
    "This notebook explores the Cats vs Dogs dataset and visualizes sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each split\n",
    "data_dir = Path('../data/processed')\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = data_dir / split\n",
    "    if split_dir.exists():\n",
    "        cat_count = len(list((split_dir / 'cat').glob('*.jpg')))\n",
    "        dog_count = len(list((split_dir / 'dog').glob('*.jpg')))\n",
    "        print(f\"{split.capitalize()}: {cat_count} cats, {dog_count} dogs, Total: {cat_count + dog_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(data_dir, split='train', n_samples=8):\n",
    "    \"\"\"Display sample images from the dataset.\"\"\"\n",
    "    \n",
    "    split_dir = Path(data_dir) / split\n",
    "    \n",
    "    # Get sample images\n",
    "    cat_images = list((split_dir / 'cat').glob('*.jpg'))[:n_samples//2]\n",
    "    dog_images = list((split_dir / 'dog').glob('*.jpg'))[:n_samples//2]\n",
    "    \n",
    "    images = cat_images + dog_images\n",
    "    labels = ['Cat'] * len(cat_images) + ['Dog'] * len(dog_images)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, n_samples//2, figsize=(15, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (img_path, label) in enumerate(zip(images, labels)):\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{label}\\n{img.size[0]}x{img.size[1]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples('../data/processed', split='train', n_samples=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_sizes(data_dir, split='train', max_images=100):\n",
    "    \"\"\"Analyze distribution of image sizes.\"\"\"\n",
    "    \n",
    "    split_dir = Path(data_dir) / split\n",
    "    \n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    for class_name in ['cat', 'dog']:\n",
    "        images = list((split_dir / class_name).glob('*.jpg'))[:max_images//2]\n",
    "        for img_path in images:\n",
    "            img = Image.open(img_path)\n",
    "            widths.append(img.size[0])\n",
    "            heights.append(img.size[1])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].hist(widths, bins=30, alpha=0.7, label='Width')\n",
    "    axes[0].set_xlabel('Width (pixels)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Image Width Distribution')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].hist(heights, bins=30, alpha=0.7, label='Height', color='orange')\n",
    "    axes[1].set_xlabel('Height (pixels)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Image Height Distribution')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Width - Mean: {np.mean(widths):.0f}, Std: {np.std(widths):.0f}\")\n",
    "    print(f\"Height - Mean: {np.mean(heights):.0f}, Std: {np.std(heights):.0f}\")\n",
    "\n",
    "analyze_image_sizes('../data/processed', split='train', max_images=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Augmentation Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "def show_augmentations(image_path, n_augmentations=6):\n",
    "    \"\"\"Show augmented versions of an image.\"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    \n",
    "    # Create augmentation generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Generate augmented images\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(img_array, batch_size=1):\n",
    "        axes[i].imshow(batch[0].astype('uint8'))\n",
    "        axes[i].set_title(f'Augmentation {i+1}')\n",
    "        axes[i].axis('off')\n",
    "        i += 1\n",
    "        if i >= n_augmentations:\n",
    "            break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show augmentations for a sample image\n",
    "sample_image = list((Path('../data/processed/train/cat')).glob('*.jpg'))[0]\n",
    "show_augmentations(sample_image, n_augmentations=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Predictions (After Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can be used after training the model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model('../models/cats_dogs_classifier.h5')\n",
    "\n",
    "def predict_and_show(image_path, model):\n",
    "    \"\"\"Make prediction and show image.\"\"\"\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)[0][0]\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {'Dog' if prediction > 0.5 else 'Cat'}\\nConfidence: {max(prediction, 1-prediction):.2%}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Test on a sample image\n",
    "test_image = list((Path('../data/processed/test/cat')).glob('*.jpg'))[0]\n",
    "predict_and_show(test_image, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
